{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model123.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the packages"
      ],
      "metadata": {
        "id": "HzwrZYEc6E09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "import time\n",
        "from torchvision import models,datasets, transforms\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "import torch.nn as nn\n",
        "from torch.autograd.function import Function\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n"
      ],
      "metadata": {
        "id": "Qg6V3vXG6FCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load Office-Caltech-10 dataset"
      ],
      "metadata": {
        "id": "Q135fs56ERSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You need to download [Office-Caltech-10 DeCAF-fc6 features](https://drive.google.com/drive/folders/1XAKj5ikc6ygcanexeiWuwvnHMf5rUVGy) generated in [1] to run this code. Then: \n",
        "\n",
        "\n",
        "2.1. If you run the code on Colab, you will need to put the data in the corresponding folder of your [Google Drive](https://drive.google.com/drive/u/0/my-drive).\n",
        "\n",
        "\n",
        "2.2. If you run the code locally, you will need to put the data in the corresponding folder of your device.\n",
        "\n",
        "\n",
        "\n",
        "[1] Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell, T. (2014, January). Decaf: A deep convolutional activation feature for generic visual recognition. In International conference on machine learning (pp. 647-655). PMLR."
      ],
      "metadata": {
        "id": "kqFLxQQJEWRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google drive, please ignore this cell if you run the code locally.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzZTJwFkEXxZ",
        "outputId": "f45364cd-ba37-4fad-f9d7-1863d1e9ebbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edfyP3eE3LRV"
      },
      "outputs": [],
      "source": [
        "amazon = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/amazon_fc6.mat')\n",
        "webcam = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/webcam_fc6.mat')\n",
        "dslr = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/dslr_fc6.mat')\n",
        "cal  = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/caltech_decaf.mat')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_fts,amazon_labels=amazon['fts'],amazon['labels'].reshape(-1)-1\n",
        "webcam_fts,webcam_labels=webcam['fts'],webcam['labels'].reshape(-1)-1\n",
        "dslr_fts,dslr_labels=dslr['fts'],dslr['labels'].reshape(-1)-1\n",
        "cal_fts,cal_labels=cal['feas'],cal['labels'].reshape(-1)-1"
      ],
      "metadata": {
        "id": "GiY4IIuG8jqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cal_labels)\n",
        "print(webcam_labels.shape)\n",
        "print(dslr_labels.shape)\n",
        "print(cal_labels.shape)\n",
        "n_class=10"
      ],
      "metadata": {
        "id": "Vcfz7qjD9MFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f1a897-b875-4cb5-cea5-136190f10b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 9 9 9]\n",
            "(795,)\n",
            "(498,)\n",
            "(1123,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define functions to formulate the training and testing sets"
      ],
      "metadata": {
        "id": "pn_Vricr_Uof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice\n",
        "class_set=np.array([1,2,6,11,12,13,16,17,18,23])-1\n",
        "#backpack, bike, calculator, headphones, keyboard, laptop-computer, monitor, mouse, mu, and projector\n",
        "\n",
        "def get_data(domain_name):\n",
        "  index=np.array([])\n",
        "  label_for_training=[]\n",
        "  fts,labels=None, None\n",
        "  if domain_name=='amazon':\n",
        "    fts,labels=amazon_fts,amazon_labels\n",
        "  elif domain_name=='webcam':\n",
        "    fts,labels=webcam_fts,webcam_labels\n",
        "  elif domain_name=='dslr':\n",
        "    fts,labels=dslr_fts,dslr_labels\n",
        "\n",
        "  j=0\n",
        "  for i in class_set:\n",
        "    index=np.hstack((index,np.where(labels==i)[0]))\n",
        "    for a in np.where(labels==i)[0]:\n",
        "      label_for_training.append(j)\n",
        "    j=j+1\n",
        "  index=index.astype(int)\n",
        "  return fts[index],np.array(label_for_training)\n",
        "\n",
        "def get_index(feature,labels,select_num):\n",
        "  select_list=np.array([])\n",
        "  remaining_list=np.array([])\n",
        "  for i in range(10):\n",
        "    full_list=np.where(labels==i)[0]\n",
        "    ran_select=np.random.choice(full_list,select_num,replace=False)\n",
        "    select_list=np.hstack((select_list,ran_select))\n",
        "\n",
        "    remain_list=np.setdiff1d(full_list,ran_select)\n",
        "    remaining_list=np.hstack((remaining_list,remain_list))\n",
        "  return select_list.astype(int),remaining_list.astype(int)\n",
        "\n",
        "\n",
        "def souce_target_split(src_name, tar_name):\n",
        "  if src_name =='cad':\n",
        "    src_fea,src_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "    src_fea,src_label=get_data(src_name)\n",
        "  if tar_name == 'cad':\n",
        "    tar_fea,tar_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "\n",
        "    tar_fea,tar_label=get_data(tar_name)\n",
        "  if src_name=='amazon':\n",
        "    scr_number=20\n",
        "  elif src_name=='cad':\n",
        "    scr_number=20\n",
        "  else:\n",
        "    scr_number=8\n",
        "  tar_number=3\n",
        "  \n",
        "  src_select,src_remain=get_index(src_fea,src_label,scr_number)\n",
        "  tar_select,tar_remain=get_index(tar_fea,tar_label,tar_number)\n",
        "\n",
        "  return src_fea[src_select],src_label[src_select],tar_fea[tar_select],tar_label[tar_select],tar_fea[tar_remain],tar_label[tar_remain]\n",
        "\n"
      ],
      "metadata": {
        "id": "nUHz0kZd_ZpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Self-defined layer for implementing Center Loss"
      ],
      "metadata": {
        "id": "t7AV-vx4-eKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CenterLoss(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim, size_average=True):\n",
        "        super(CenterLoss, self).__init__()\n",
        "        self.centers = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
        "        self.centerlossfunc = CenterlossFunc.apply\n",
        "        self.feat_dim = feat_dim\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, label, feat):\n",
        "        batch_size = feat.size(0)\n",
        "        feat = feat.view(batch_size, -1)\n",
        "        # To check the dim of centers and features\n",
        "        if feat.size(1) != self.feat_dim:\n",
        "            raise ValueError(\"Center's dim: {0} should be equal to input feature's \\\n",
        "                            dim: {1}\".format(self.feat_dim,feat.size(1)))\n",
        "        batch_size_tensor = feat.new_empty(1).fill_(batch_size if self.size_average else 1)\n",
        "        loss = self.centerlossfunc(feat, label, self.centers, batch_size_tensor)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CenterlossFunc(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, feature, label, centers, batch_size):\n",
        "        ctx.save_for_backward(feature, label, centers, batch_size)\n",
        "        centers_batch = centers.index_select(0, label.long())\n",
        "        return (feature - centers_batch).pow(2).sum() / 2.0 / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        feature, label, centers, batch_size = ctx.saved_tensors\n",
        "        centers_batch = centers.index_select(0, label.long())\n",
        "        diff = centers_batch - feature\n",
        "        # init every iteration\n",
        "        counts = centers.new_ones(centers.size(0))\n",
        "        ones = centers.new_ones(label.size(0))\n",
        "        grad_centers = centers.new_zeros(centers.size())\n",
        "\n",
        "        counts = counts.scatter_add_(0, label.long(), ones)\n",
        "        grad_centers.scatter_add_(0, label.unsqueeze(1).expand(feature.size()).long(), diff)\n",
        "        grad_centers = grad_centers/counts.view(-1, 1)\n",
        "        return - grad_output * diff / batch_size, None, grad_centers / batch_size, None\n",
        "\n",
        "#Testing function\n",
        "def main(test_cuda=False):\n",
        "    print('-'*80)\n",
        "    device = torch.device(\"cuda\" if test_cuda else \"cpu\")\n",
        "    ct = CenterLoss(10,2,size_average=True).to(device)\n",
        "    y = torch.Tensor([0,0,2,1]).to(device)\n",
        "    feat = torch.zeros(4,2).to(device).requires_grad_()\n",
        "    print (list(ct.parameters()))\n",
        "    \n",
        "    print (ct.centers.grad)\n",
        "    out = ct(y,feat)\n",
        "    print(out.item())\n",
        "    out.backward()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.manual_seed(999)\n",
        "    main(test_cuda=False)\n",
        "    if torch.cuda.is_available():\n",
        "        main(test_cuda=True)"
      ],
      "metadata": {
        "id": "ta9VCmoLmWXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f123b998-77fb-4223-d3ac-430de26d39ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "[Parameter containing:\n",
            "tensor([[-0.2528,  1.4072],\n",
            "        [ 0.2910,  1.0365],\n",
            "        [ 0.6396, -1.0857],\n",
            "        [-1.6153,  1.5635],\n",
            "        [ 0.1878, -0.9564],\n",
            "        [-0.2440, -0.4153],\n",
            "        [ 0.3259, -1.6059],\n",
            "        [-0.5272,  0.3401],\n",
            "        [-1.6526,  0.2108],\n",
            "        [-1.3302,  0.4676]], requires_grad=True)]\n",
            "None\n",
            "0.8543729186058044\n",
            "--------------------------------------------------------------------------------\n",
            "[Parameter containing:\n",
            "tensor([[ 0.9147, -1.1896],\n",
            "        [-0.7501, -1.5465],\n",
            "        [-0.4303,  0.3703],\n",
            "        [ 0.4588,  0.2950],\n",
            "        [ 0.2126, -0.1098],\n",
            "        [-0.1349,  2.0038],\n",
            "        [ 1.8339,  2.3544],\n",
            "        [ 0.3990, -0.3584],\n",
            "        [-0.2116,  0.5276],\n",
            "        [ 0.5683, -0.6786]], device='cuda:0', requires_grad=True)]\n",
            "None\n",
            "0.9725638628005981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Define the network"
      ],
      "metadata": {
        "id": "qik25SixFRVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(4096, 1024)\n",
        "        self.act1= nn.PReLU()\n",
        "        self.layer2 = nn.Linear(1024, 128)\n",
        "        self.act2= nn.PReLU()\n",
        "        self.ip2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.layer1(x)\n",
        "        x = self.act1(x)\n",
        "        feature = self.layer2(x)\n",
        "        feature = self.act2(feature)\n",
        "        ip2 = self.ip2(feature)\n",
        "        return feature , ip2\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "hsd82Fe79MvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define the function for training and testing "
      ],
      "metadata": {
        "id": "JMPyacYVn2cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainandtest(model, dataloaders, optimizer,loss_weight):\n",
        "    device = torch.device(\"cuda\")\n",
        "    centerloss = CenterLoss(31, 128).to(device)\n",
        "    optimzer4center = torch.optim.SGD(centerloss.parameters(), lr =0.5)\n",
        "    n_epoch = 150\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    early_stop = 20\n",
        "    since = time.time()\n",
        "    best_acc = 0\n",
        "    stop = 0\n",
        "    for epoch in range(0, n_epoch):\n",
        "        stop += 1\n",
        "        for phase in ['src']:\n",
        "            if phase == 'src':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            total_loss, total_center,correct = 0, 0,0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels= inputs.cuda(),labels.cuda()\n",
        "                optimizer.zero_grad()\n",
        "                optimzer4center.zero_grad()\n",
        "\n",
        "\n",
        "    \n",
        "                with torch.set_grad_enabled(phase == 'src'):\n",
        "                    ip1, outputs = model(inputs)\n",
        "                    softmax=criterion(outputs, labels)\n",
        "                    centerlss=centerloss(labels,ip1)\n",
        "                    loss = softmax + loss_weight * centerlss\n",
        "                preds = torch.max(outputs, 1)[1]\n",
        "                if phase == 'src':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    optimzer4center.step()\n",
        "                total_loss += softmax.item() * inputs.size(0)\n",
        "                total_center +=centerlss.item()\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "            epoch_loss = total_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = correct.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in dataloaders['tar']:\n",
        "          inputs, labels= inputs.cuda(),labels.cuda()\n",
        "          ip1, outputs = model(inputs)\n",
        "          preds = torch.max(outputs, 1)[1]\n",
        "          correct += torch.sum(preds == labels.data)\n",
        "        epoch_acc = correct.double() / len(dataloaders['tar'].dataset)\n",
        "        if epoch>145:\n",
        "          print('Testing acc:',epoch_acc.item())\n",
        "          print(f'Epoch: [{epoch:02d}/{n_epoch:02d}]---{phase}, softmax_loss: {epoch_loss:.6f}')\n",
        "          print_center = total_center / len(dataloaders[phase].dataset)\n",
        "          print('centerloss:',print_center)\n",
        "\n",
        "    time_pass = time.time() - since\n",
        "    print(f'Training complete in {time_pass // 60:.0f}m {time_pass % 60:.0f}s')\n"
      ],
      "metadata": {
        "id": "R3lDkzLbn7zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Define evaluation function"
      ],
      "metadata": {
        "id": "XgkHb3lmGL-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(types,domain_src,domain_tar,weight,seeds):\n",
        "  batch_size = 32\n",
        "  n_class=10\n",
        "  random.seed(seeds)\n",
        "  train_x_scr,train_y_scr,train_x_tar,train_y_tar,test_x_tar,test_y_tar=souce_target_split(domain_src, domain_tar)\n",
        "  if types==\"sourceonly\":\n",
        "    x_train=train_x_scr\n",
        "    y_train=train_y_scr\n",
        "  else:\n",
        "    x_train=np.vstack((train_x_scr,train_x_tar)) \n",
        "    y_train=np.hstack((train_y_scr,train_y_tar))\n",
        "  print(len(x_train))\n",
        "  \n",
        "  x_test=test_x_tar\n",
        "  y_test=test_y_tar\n",
        "  print(len(x_test))\n",
        "  x_train=torch.from_numpy(x_train)\n",
        "  y_train=torch.from_numpy(y_train)\n",
        "  x_test=torch.from_numpy(x_test)\n",
        "  y_test=torch.from_numpy(y_test)\n",
        "  x_train=x_train.float()\n",
        "  x_test=x_test.float()\n",
        "  y_train=y_train.long()\n",
        "  y_test=y_test.long()\n",
        "  # form the dataset\n",
        "  train_dataset=TensorDataset(x_train,y_train)\n",
        "  val_dataset=TensorDataset(x_test,y_test)\n",
        "  train_loader= DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "  test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  model = Net().cuda()\n",
        "  param_group = []\n",
        "  learning_rate = 0.0001\n",
        "  momentum = 5e-4\n",
        "  for k, v in model.named_parameters():\n",
        "\n",
        "\n",
        "    if k.__contains__('classifier'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "    elif k.__contains__('ip'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "\n",
        "    else:\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "\n",
        "\n",
        "  print('Types:',types)\n",
        "  # optimizer = torch.optim.SGD(param_group, momentum=momentum)\n",
        "  optimizer = torch.optim.Adam(param_group)\n",
        "  dataloaders = {'src': train_loader,\n",
        "               'tar': test_loader}\n",
        "  trainandtest(model, dataloaders, optimizer,weight)\n"
      ],
      "metadata": {
        "id": "YqDbBpFkn-m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Example"
      ],
      "metadata": {
        "id": "C87J1y9xGOLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples below are baseline Models 1, 2, and 3 on the *Amaon and DSLR* domain adaptation task.\n",
        "You may change the value of variables to get other experimental results.\n",
        "\n",
        "Note that models will be trained from scratch. Training time should last for around **6 minutes** for one repetition if you use the GPU (GeForce RTX 3090).\n",
        "\n",
        "Although the results you get may be slightly different from the ones of the manuscript due to randomized initialization, the gap should be small."
      ],
      "metadata": {
        "id": "NhqOiuIAGQo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='sourceonly'\n",
        "source_domain='amazon'\n",
        "target_domain='dslr'\n",
        "random_seed=1\n",
        "weight=0\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)"
      ],
      "metadata": {
        "id": "ncFWQ_RKoQmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e78485-ba9d-43fd-b6b8-f6c7ec9d14a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "127\n",
            "Types: sourceonly\n",
            "Testing acc: 0.6929133858267716\n",
            "Epoch: [146/150]---src, softmax_loss: 0.000050\n",
            "centerloss: 16.87419448852539\n",
            "Testing acc: 0.6929133858267716\n",
            "Epoch: [147/150]---src, softmax_loss: 0.000049\n",
            "centerloss: 17.22310592651367\n",
            "Testing acc: 0.6929133858267716\n",
            "Epoch: [148/150]---src, softmax_loss: 0.000049\n",
            "centerloss: 18.52044708251953\n",
            "Testing acc: 0.6929133858267716\n",
            "Epoch: [149/150]---src, softmax_loss: 0.000048\n",
            "centerloss: 17.246609344482422\n",
            "Training complete in 0m 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='softmax'\n",
        "source_domain='amazon'\n",
        "target_domain='dslr'\n",
        "random_seed=1\n",
        "weight=0\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)\n"
      ],
      "metadata": {
        "id": "eEZNYPFqpeRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dde79b0-b403-4dca-bc5d-ec73268d29b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230\n",
            "127\n",
            "Types: softmax\n",
            "Testing acc: 0.8740157480314961\n",
            "Epoch: [146/150]---src, softmax_loss: 0.000092\n",
            "centerloss: 14.088780411430028\n",
            "Testing acc: 0.8740157480314961\n",
            "Epoch: [147/150]---src, softmax_loss: 0.000091\n",
            "centerloss: 14.437496682871943\n",
            "Testing acc: 0.8818897637795275\n",
            "Epoch: [148/150]---src, softmax_loss: 0.000090\n",
            "centerloss: 14.078015932829484\n",
            "Testing acc: 0.8818897637795275\n",
            "Epoch: [149/150]---src, softmax_loss: 0.000089\n",
            "centerloss: 14.476233706266983\n",
            "Training complete in 0m 60s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='center loss'\n",
        "source_domain='amazon'\n",
        "target_domain='dslr'\n",
        "random_seed=1\n",
        "weight=0.01\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi8499hUI2yx",
        "outputId": "15224e3b-4fd2-45fc-9497-e2545c27710e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230\n",
            "127\n",
            "Types: center loss\n",
            "Testing acc: 0.9291338582677166\n",
            "Epoch: [146/150]---src, softmax_loss: 0.003837\n",
            "centerloss: 0.054520971878715185\n",
            "Testing acc: 0.9212598425196851\n",
            "Epoch: [147/150]---src, softmax_loss: 0.003775\n",
            "centerloss: 0.05364571706108425\n",
            "Testing acc: 0.9212598425196851\n",
            "Epoch: [148/150]---src, softmax_loss: 0.003773\n",
            "centerloss: 0.058090983266415805\n",
            "Testing acc: 0.9133858267716535\n",
            "Epoch: [149/150]---src, softmax_loss: 0.003735\n",
            "centerloss: 0.05936995952025704\n",
            "Training complete in 1m 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='sourceonly'\n",
        "source_domain='dslr'\n",
        "target_domain='amazon'\n",
        "random_seed=1\n",
        "weight=0\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9rUmu3AI6Ov",
        "outputId": "7132d973-1b1b-42bf-aaab-4066878ed64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n",
            "928\n",
            "Types: sourceonly\n",
            "Testing acc: 0.7079741379310345\n",
            "Epoch: [146/150]---src, softmax_loss: 0.000045\n",
            "centerloss: 11.218095779418945\n",
            "Testing acc: 0.7079741379310345\n",
            "Epoch: [147/150]---src, softmax_loss: 0.000045\n",
            "centerloss: 11.00118408203125\n",
            "Testing acc: 0.7079741379310345\n",
            "Epoch: [148/150]---src, softmax_loss: 0.000045\n",
            "centerloss: 11.005870819091797\n",
            "Testing acc: 0.7079741379310345\n",
            "Epoch: [149/150]---src, softmax_loss: 0.000044\n",
            "centerloss: 11.649832916259765\n",
            "Training complete in 0m 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='softmax'\n",
        "source_domain='dslr'\n",
        "target_domain='amazon'\n",
        "random_seed=1\n",
        "weight=0\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvZ1iTjqN4vU",
        "outputId": "ce247adc-0134-4ea0-b023-3ac8aeff1cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n",
            "928\n",
            "Types: softmax\n",
            "Testing acc: 0.8760775862068966\n",
            "Epoch: [146/150]---src, softmax_loss: 0.000052\n",
            "centerloss: 15.379467496004972\n",
            "Testing acc: 0.8760775862068966\n",
            "Epoch: [147/150]---src, softmax_loss: 0.000051\n",
            "centerloss: 15.728529774058948\n",
            "Testing acc: 0.8760775862068966\n",
            "Epoch: [148/150]---src, softmax_loss: 0.000051\n",
            "centerloss: 16.27083046653054\n",
            "Testing acc: 0.8760775862068966\n",
            "Epoch: [149/150]---src, softmax_loss: 0.000050\n",
            "centerloss: 16.24046408913352\n",
            "Training complete in 1m 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "types='center loss'\n",
        "source_domain='dslr'\n",
        "target_domain='amazon'\n",
        "random_seed=1\n",
        "weight=0.01\n",
        "evaluate(types,source_domain,target_domain,weight,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f-r34qbN6kg",
        "outputId": "86c1f9fb-7f3f-49d9-d62c-7b370b0a6ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n",
            "928\n",
            "Types: center loss\n",
            "Testing acc: 0.8717672413793104\n",
            "Epoch: [146/150]---src, softmax_loss: 0.007156\n",
            "centerloss: 0.02275822108442133\n",
            "Testing acc: 0.8674568965517241\n",
            "Epoch: [147/150]---src, softmax_loss: 0.007148\n",
            "centerloss: 0.022035855054855346\n",
            "Testing acc: 0.8706896551724138\n",
            "Epoch: [148/150]---src, softmax_loss: 0.006973\n",
            "centerloss: 0.022360619631680574\n",
            "Testing acc: 0.8706896551724138\n",
            "Epoch: [149/150]---src, softmax_loss: 0.006926\n",
            "centerloss: 0.0220579131083055\n",
            "Training complete in 1m 9s\n"
          ]
        }
      ]
    }
  ]
}