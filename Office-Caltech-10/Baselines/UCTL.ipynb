{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCTL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the packages"
      ],
      "metadata": {
        "id": "HzwrZYEc6E09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision\n",
        "import time\n",
        "from torchvision import models,datasets, transforms\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "import torch.nn as nn\n",
        "from torch.autograd.function import Function\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n"
      ],
      "metadata": {
        "id": "Qg6V3vXG6FCz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load Office-Caltech-10 dataset"
      ],
      "metadata": {
        "id": "ek0IWA_ASWqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You need to download [Office-Caltech-10 DeCAF-fc6 features](https://drive.google.com/drive/folders/1XAKj5ikc6ygcanexeiWuwvnHMf5rUVGy) generated in [1] to run this code. Then: \n",
        "\n",
        "\n",
        "2.1. If you run the code on Colab, you will need to put the data in the corresponding folder of your [Google Drive](https://drive.google.com/drive/u/0/my-drive).\n",
        "\n",
        "\n",
        "2.2. If you run the code locally, you will need to put the data in the corresponding folder of your device.\n",
        "\n",
        "\n",
        "\n",
        "[1] Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell, T. (2014, January). Decaf: A deep convolutional activation feature for generic visual recognition. In International conference on machine learning (pp. 647-655). PMLR."
      ],
      "metadata": {
        "id": "hrKPziXjSYbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google drive, please ignore this cell if you run the code locally.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrGdoV6BSb4P",
        "outputId": "a4cd084e-64e0-43e8-d9cd-83d79e7feab1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "edfyP3eE3LRV"
      },
      "outputs": [],
      "source": [
        "amazon = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/amazon_fc6.mat')\n",
        "webcam = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/webcam_fc6.mat')\n",
        "dslr = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/dslr_fc6.mat')\n",
        "cal  = scipy.io.loadmat('/content/drive/MyDrive/office-31/fc6/caltech_decaf.mat')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_fts,amazon_labels=amazon['fts'],amazon['labels'].reshape(-1)-1\n",
        "webcam_fts,webcam_labels=webcam['fts'],webcam['labels'].reshape(-1)-1\n",
        "dslr_fts,dslr_labels=dslr['fts'],dslr['labels'].reshape(-1)-1\n",
        "cal_fts,cal_labels=cal['feas'],cal['labels'].reshape(-1)-1"
      ],
      "metadata": {
        "id": "GiY4IIuG8jqs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cal_labels)\n",
        "print(webcam_labels.shape)\n",
        "print(dslr_labels.shape)\n",
        "print(cal_labels.shape)\n",
        "n_class=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcfz7qjD9MFd",
        "outputId": "bdc169c6-0f6b-4ccf-b6b9-ceb2d8b368da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 9 9 9]\n",
            "(795,)\n",
            "(498,)\n",
            "(1123,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define functions to formulate the training and testing sets"
      ],
      "metadata": {
        "id": "pn_Vricr_Uof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice\n",
        "class_set=np.array([1,2,6,11,12,13,16,17,18,23])-1\n",
        "#backpack, bike, calculator, headphones, keyboard, laptop-computer, monitor, mouse, mu, and projector\n",
        "\n",
        "def get_data(domain_name):\n",
        "  index=np.array([])\n",
        "  label_for_training=[]\n",
        "  fts,labels=None, None\n",
        "  if domain_name=='amazon':\n",
        "    fts,labels=amazon_fts,amazon_labels\n",
        "  elif domain_name=='webcam':\n",
        "    fts,labels=webcam_fts,webcam_labels\n",
        "  elif domain_name=='dslr':\n",
        "    fts,labels=dslr_fts,dslr_labels\n",
        "\n",
        "  j=0\n",
        "  for i in class_set:\n",
        "    index=np.hstack((index,np.where(labels==i)[0]))\n",
        "    for a in np.where(labels==i)[0]:\n",
        "      label_for_training.append(j)\n",
        "    j=j+1\n",
        "  index=index.astype(int)\n",
        "  return fts[index],np.array(label_for_training)\n",
        "\n",
        "def get_index(feature,labels,select_num):\n",
        "  select_list=np.array([])\n",
        "  remaining_list=np.array([])\n",
        "  for i in range(10):\n",
        "    full_list=np.where(labels==i)[0]\n",
        "    ran_select=np.random.choice(full_list,select_num,replace=False)\n",
        "    select_list=np.hstack((select_list,ran_select))\n",
        "\n",
        "\n",
        "    remain_list=np.setdiff1d(full_list,ran_select)\n",
        "    remaining_list=np.hstack((remaining_list,remain_list))\n",
        "  return select_list.astype(int),remaining_list.astype(int)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def souce_target_split(src_name, tar_name):\n",
        "  if src_name =='cad':\n",
        "    src_fea,src_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "    src_fea,src_label=get_data(src_name)\n",
        "  if tar_name == 'cad':\n",
        "    tar_fea,tar_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "    tar_fea,tar_label=get_data(tar_name)\n",
        "\n",
        "  if src_name=='amazon':\n",
        "    scr_number=20\n",
        "  elif src_name=='cad':\n",
        "    scr_number=20\n",
        "  else:\n",
        "    scr_number=8\n",
        "  tar_number=3\n",
        "  \n",
        "  src_select,src_remain=get_index(src_fea,src_label,scr_number)\n",
        "  tar_select,tar_remain=get_index(tar_fea,tar_label,tar_number)\n",
        "\n",
        "\n",
        "\n",
        "  return src_fea[src_select],src_label[src_select],tar_fea[tar_select],tar_label[tar_select],tar_fea[tar_remain],tar_label[tar_remain]\n",
        "\n"
      ],
      "metadata": {
        "id": "nUHz0kZd_ZpM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Self-defined layer for implementing unweighted center transfer loss (UCTL)"
      ],
      "metadata": {
        "id": "t7AV-vx4-eKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UCTL(nn.Module):\n",
        "    def __init__(self, num_classes, feat_dim, size_average=True):\n",
        "        super(UCTL, self).__init__()\n",
        "        self.centers = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
        "        self.centerlossfunc = CenterlossFunc.apply\n",
        "        self.feat_dim = feat_dim\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, label, flip_label, feat):\n",
        "        batch_size = feat.size(0)\n",
        "        feat = feat.view(batch_size, -1)\n",
        "        # To check the dim of centers and features\n",
        "        if feat.size(1) != self.feat_dim:\n",
        "            raise ValueError(\"Center's dim: {0} should be equal to input feature's \\\n",
        "                            dim: {1}\".format(self.feat_dim,feat.size(1)))\n",
        "        batch_size_tensor = feat.new_empty(1).fill_(batch_size if self.size_average else 1)\n",
        "        loss = self.centerlossfunc(feat, label,flip_label, self.centers, batch_size_tensor)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class CenterlossFunc(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, feature, label,flip_label, centers, batch_size):\n",
        "        ctx.save_for_backward(feature, label,flip_label, centers, batch_size)\n",
        "        centers_batch = centers.index_select(0, flip_label.long())\n",
        "        return (feature - centers_batch).pow(2).sum() / (2.0 * batch_size)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        feature,label,flip_label,centers,batch_size = ctx.saved_tensors\n",
        "        flip_centers_batch = centers.index_select(0, flip_label.long())\n",
        "        flip_diff=flip_centers_batch-feature\n",
        "\n",
        "\n",
        "        centers_batch = centers.index_select(0, label.long())\n",
        "        diff = centers_batch - feature\n",
        "        # init every iteration\n",
        "        counts = centers.new_ones(centers.size(0))\n",
        "        ones = centers.new_ones(label.size(0))\n",
        "        grad_centers = centers.new_zeros(centers.size())\n",
        "        counts = counts.scatter_add_(0, label.long(), ones)-1+0.0001\n",
        "\n",
        "        grad_centers.scatter_add_(0, label.unsqueeze(1).expand(feature.size()).long(), diff)\n",
        "        grad_centers = grad_centers/counts.view(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "        return - grad_output * flip_diff / batch_size, None, None,grad_centers / batch_size, None\n",
        "\n",
        "#Testing function\n",
        "def main(test_cuda=False):\n",
        "    print('-'*80)\n",
        "    device = torch.device(\"cuda\" if test_cuda else \"cpu\")\n",
        "    ct = UCTL(20,2,size_average=True).to(device)\n",
        "    y = torch.Tensor([0,0,2,1,3]).to(device)\n",
        "    feat = torch.zeros(5,2).to(device).requires_grad_()\n",
        "    print(list(ct.parameters()))\n",
        "    \n",
        "    print(ct.centers.grad)\n",
        "    out = ct(y,y,feat)\n",
        "    print(out.item())\n",
        "    out.backward()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.manual_seed(999)\n",
        "    if torch.cuda.is_available():\n",
        "        main(test_cuda=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta9VCmoLmWXW",
        "outputId": "f81fe20c-3f77-4bf6-f3ee-03cecf20234f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "[Parameter containing:\n",
            "tensor([[-0.2528,  1.4072],\n",
            "        [ 0.2910,  1.0365],\n",
            "        [-0.9816, -3.4219],\n",
            "        [ 1.4910,  0.2422],\n",
            "        [ 1.4832, -0.3704],\n",
            "        [ 0.0941,  2.1528],\n",
            "        [ 0.6271, -1.1666],\n",
            "        [-0.7862,  0.0759],\n",
            "        [-0.0086, -0.6568],\n",
            "        [-1.0011,  0.2992],\n",
            "        [ 0.6396, -1.0857],\n",
            "        [-1.6153,  1.5635],\n",
            "        [ 0.8194,  0.6117],\n",
            "        [ 0.7602,  1.4788],\n",
            "        [ 1.9647,  0.9414],\n",
            "        [ 0.3883, -0.3957],\n",
            "        [ 0.5920, -2.8563],\n",
            "        [-0.4750, -0.9978],\n",
            "        [ 0.0489,  0.9250],\n",
            "        [-1.2278, -0.9470]], device='cuda:0', requires_grad=True)]\n",
            "None\n",
            "2.02020525932312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Define the network"
      ],
      "metadata": {
        "id": "LkLocd5qTZcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(4096, 1024)\n",
        "        self.act1= nn.PReLU()\n",
        "        self.layer2 = nn.Linear(1024, 128)\n",
        "        self.act2= nn.PReLU()\n",
        "        self.ip2 = nn.Linear(128, 10)\n",
        "  \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.layer1(x)\n",
        "        x = self.act1(x)\n",
        "        feature = self.layer2(x)\n",
        "        feature = self.act2(feature)\n",
        "        ip2 = self.ip2(feature)\n",
        "        return feature , ip2\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "hsd82Fe79MvF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "RAND_TENSOR = torch.randn(1,4096).cuda()\n",
        "device = torch.device(\"cuda\")\n",
        "net = Net().to(device)\n",
        "output = net(RAND_TENSOR)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOWr4Qv49M1s",
        "outputId": "343e08df-f62e-4d9b-af7e-6e1996fd3773"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.0677, -0.0192, -0.0805,  0.0260,  0.4609, -0.0321,  0.2013, -0.2339,\n",
            "         -0.0389, -0.0053, -0.1083, -0.0702, -0.0596, -0.0726, -0.0100, -0.0579,\n",
            "         -0.0828,  0.2763,  0.1673,  0.2522,  0.0976,  0.2203, -0.0322,  0.2110,\n",
            "         -0.1069,  0.0598, -0.0717, -0.0466, -0.0096, -0.0692, -0.0309,  0.2684,\n",
            "          0.1574,  0.1915, -0.0473, -0.0758, -0.0139, -0.0066,  0.1226, -0.0404,\n",
            "         -0.0078, -0.0276,  0.0065,  0.5099, -0.0108, -0.0239, -0.0147, -0.0595,\n",
            "          0.0182, -0.0728, -0.0201, -0.0735, -0.0520,  0.1534, -0.0087,  0.2444,\n",
            "          0.2740,  0.1030,  0.0501,  0.1275, -0.0252,  0.0831,  0.2448, -0.0804,\n",
            "         -0.0209,  0.1519, -0.0112,  0.1368, -0.0441, -0.0923,  0.3843,  0.2096,\n",
            "          0.0447,  0.0806,  0.1171, -0.0418,  0.1088, -0.0266, -0.0901, -0.0295,\n",
            "          0.0962, -0.0610,  0.2959, -0.0715, -0.0467,  0.6762,  0.0219,  0.0324,\n",
            "         -0.0392, -0.0271, -0.0570, -0.0722, -0.1474,  0.0327, -0.0468,  0.3923,\n",
            "          0.2851, -0.0778,  0.1192, -0.0732, -0.0688,  0.1563,  0.1029,  0.0365,\n",
            "         -0.0080, -0.0321, -0.0414, -0.0316, -0.0633, -0.0912, -0.0940,  0.1671,\n",
            "         -0.0019,  0.0289, -0.0631, -0.0944,  0.0086, -0.0117, -0.0613, -0.1311,\n",
            "         -0.0667,  0.2161,  0.3667,  0.1763, -0.0169, -0.0681, -0.0616, -0.0039]],\n",
            "       device='cuda:0', grad_fn=<PreluBackward0>), tensor([[ 0.0602, -0.0088,  0.0901, -0.1731, -0.1722,  0.0186, -0.0541,  0.0869,\n",
            "          0.1774,  0.1157]], device='cuda:0', grad_fn=<AddmmBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define the function for training and testing "
      ],
      "metadata": {
        "id": "JMPyacYVn2cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainandtest(model, dataloaders, optimizer,loss_weight):\n",
        "    n_class=10\n",
        "    uctl = UCTL(n_class*2, 128).to(device)\n",
        "    optimzer4center = torch.optim.SGD(uctl.parameters(), lr =0.5)\n",
        "    n_epoch = 150\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    early_stop = 20\n",
        "    since = time.time()\n",
        "    best_acc = 0\n",
        "    stop = 0\n",
        "    max_acc=[]\n",
        "    for epoch in range(0, n_epoch):\n",
        "        stop += 1\n",
        "\n",
        "        for phase in ['src']:\n",
        "            if phase == 'src':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            total_loss, total_center,correct = 0, 0,0\n",
        "            for inputs, labels,good_ord,flip_ord in dataloaders[phase]:\n",
        "                inputs, labels,good_ord,flip_ord = inputs.cuda(),labels.cuda(), good_ord.cuda(),flip_ord.cuda()\n",
        "                optimizer.zero_grad()\n",
        "                optimzer4center.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'src'):\n",
        "                    ip1, outputs = model(inputs)\n",
        "                    softmax=criterion(outputs, labels)\n",
        "                    centerlss=uctl(good_ord, flip_ord,ip1)\n",
        "                    loss = softmax + loss_weight * centerlss\n",
        "                preds = torch.max(outputs, 1)[1]\n",
        "                if phase == 'src':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    optimzer4center.step()\n",
        "                total_loss += softmax.item() * inputs.size(0)\n",
        "                total_center +=centerlss.item()\n",
        "                correct += torch.sum(preds == labels.data)\n",
        "            epoch_loss = total_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = correct.double() / len(dataloaders[phase].dataset)\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in dataloaders['tar']:\n",
        "          inputs, labels= inputs.cuda(),labels.cuda()\n",
        "          ip1, outputs = model(inputs)\n",
        "          preds = torch.max(outputs, 1)[1]\n",
        "          correct += torch.sum(preds == labels.data)\n",
        "        epoch_acc = correct.double() / len(dataloaders['tar'].dataset)\n",
        "        if epoch>145:\n",
        "          print(f'Epoch: [{epoch:02d}/{n_epoch:02d}]---{phase}, softmax_loss: {epoch_loss:.6f}')\n",
        "          print('Testing acc:',epoch_acc.item())\n",
        "          print_center = total_center / len(dataloaders[phase])\n",
        "          print('UCTL:',print_center)\n",
        "        max_acc.append(epoch_acc)\n",
        "    print(max(max_acc))\n",
        "    time_pass = time.time() - since\n"
      ],
      "metadata": {
        "id": "R3lDkzLbn7zM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Define evaluation function"
      ],
      "metadata": {
        "id": "y3t2TdbwTb3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(domain_src,domain_tar,seeds):\n",
        "  batch_size = 32\n",
        "  n_class=10\n",
        "  random.seed(seeds) #amend if you want\n",
        "\n",
        "  train_x_scr,train_y_scr,train_x_tar,train_y_tar,test_x_tar,test_y_tar=souce_target_split(domain_src, domain_tar)\n",
        "\n",
        "  x_train=np.vstack((train_x_scr,train_x_tar))\n",
        "  y_train=np.hstack((train_y_scr,train_y_tar))\n",
        "\n",
        "\n",
        "  x_test=test_x_tar\n",
        "  y_test=test_y_tar\n",
        "  print(len(x_train))\n",
        "  print(len(x_test))\n",
        "  good_order=np.hstack((train_y_scr,train_y_tar+n_class))\n",
        "  flip_order=np.hstack((train_y_scr+n_class,train_y_tar))\n",
        "  x_train=torch.from_numpy(x_train)\n",
        "  y_train=torch.from_numpy(y_train)\n",
        "  x_test=torch.from_numpy(x_test)\n",
        "  y_test=torch.from_numpy(y_test)\n",
        "  good_order=torch.from_numpy(good_order)\n",
        "  flip_order=torch.from_numpy(flip_order)\n",
        "  x_train=x_train.float()\n",
        "  x_test=x_test.float()\n",
        "  y_train=y_train.long()\n",
        "  y_test=y_test.long()\n",
        "\n",
        "  good_order=good_order.long()\n",
        "  flip_order=flip_order.long()\n",
        "  # form the dataset\n",
        "  train_dataset=TensorDataset(x_train,y_train,good_order,flip_order)\n",
        "  val_dataset=TensorDataset(x_test,y_test)\n",
        "  train_loader= DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "  test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "  dataloaders = {'src': train_loader,\n",
        "               'tar': test_loader}\n",
        "\n",
        "\n",
        "\n",
        "  model = Net().cuda()\n",
        "  param_group = []\n",
        "  learning_rate = 0.0001\n",
        "  momentum = 5e-4\n",
        "  for k, v in model.named_parameters():\n",
        "\n",
        "\n",
        "    if k.__contains__('classifier'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "    elif k.__contains__('ip'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "\n",
        "    else:\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "  \n",
        "  optimizer = torch.optim.Adam(param_group)\n",
        "\n",
        "  trainandtest(model, dataloaders, optimizer,0.01)\n"
      ],
      "metadata": {
        "id": "YqDbBpFkn-m2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Example"
      ],
      "metadata": {
        "id": "2Ct3BOo0TeWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example below is the *Amaon and DSLR* domain adaptation task.\n",
        "You may change the value of variables to get other experimental results.\n",
        "\n",
        "Note that models will be trained from scratch. Training time should last for around **2 minutes** for one repetition if you use the GPU (GeForce RTX 3090).\n",
        "\n",
        "Although the results you get may be slightly different from the ones of the manuscript due to randomized initialization, the gap should be small."
      ],
      "metadata": {
        "id": "2xRHgoVxTeSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "source_domain='amazon'\n",
        "target_domain='dslr'\n",
        "random_seed=1\n",
        "evaluate(source_domain,target_domain,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GxIl-C4XBv2",
        "outputId": "1877fd3d-459b-42c5-dac2-d21b7993b4f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230\n",
            "127\n",
            "Epoch: [146/150]---src, softmax_loss: 0.005252\n",
            "Testing acc: 0.8818897637795275\n",
            "UCTL: 4.796296298503876\n",
            "Epoch: [147/150]---src, softmax_loss: 0.004963\n",
            "Testing acc: 0.889763779527559\n",
            "UCTL: 4.461136996746063\n",
            "Epoch: [148/150]---src, softmax_loss: 0.005597\n",
            "Testing acc: 0.905511811023622\n",
            "UCTL: 4.957630217075348\n",
            "Epoch: [149/150]---src, softmax_loss: 0.005017\n",
            "Testing acc: 0.8818897637795275\n",
            "UCTL: 4.388212293386459\n",
            "tensor(0.9291, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "source_domain='dslr'\n",
        "target_domain='amazon'\n",
        "random_seed=1\n",
        "evaluate(source_domain,target_domain,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTDK9FnNVauP",
        "outputId": "c13d1b1a-2f72-483b-abd2-b04e494dc15b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n",
            "928\n",
            "Epoch: [146/150]---src, softmax_loss: 0.007321\n",
            "Testing acc: 0.8491379310344828\n",
            "UCTL: 0.585739016532898\n",
            "Epoch: [147/150]---src, softmax_loss: 0.007259\n",
            "Testing acc: 0.8491379310344828\n",
            "UCTL: 0.5982682406902313\n",
            "Epoch: [148/150]---src, softmax_loss: 0.007121\n",
            "Testing acc: 0.8491379310344828\n",
            "UCTL: 0.5811170637607574\n",
            "Epoch: [149/150]---src, softmax_loss: 0.007021\n",
            "Testing acc: 0.8469827586206896\n",
            "UCTL: 0.5707979649305344\n",
            "tensor(0.8696, device='cuda:0', dtype=torch.float64)\n"
          ]
        }
      ]
    }
  ]
}