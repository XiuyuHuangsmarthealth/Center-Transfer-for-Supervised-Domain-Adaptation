{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d_SNE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the packages"
      ],
      "metadata": {
        "id": "fE7vNXkRb4Zf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx2MVyAOjz0n"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import torchvision\n",
        "import time\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd.function import Function\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim.lr_scheduler as lr_scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load Office-Caltech-10 dataset"
      ],
      "metadata": {
        "id": "u4tS0a31b6FG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You need to download [Office-Caltech-10 DeCAF-fc6 features](https://drive.google.com/drive/folders/1XAKj5ikc6ygcanexeiWuwvnHMf5rUVGy) generated in [1] to run this code. Then: \n",
        "\n",
        "\n",
        "2.1. If you run the code on Colab, you will need to put the data in the corresponding folder of your [Google Drive](https://drive.google.com/drive/u/0/my-drive).\n",
        "\n",
        "\n",
        "2.2. If you run the code locally, you will need to put the data in the corresponding folder of your device.\n",
        "\n",
        "\n",
        "\n",
        "[1] Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., & Darrell, T. (2014, January). Decaf: A deep convolutional activation feature for generic visual recognition. In International conference on machine learning (pp. 647-655). PMLR."
      ],
      "metadata": {
        "id": "iO_XHFnBchv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google drive, please ignore this cell if you run the code locally.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_q-wQVHd-hN",
        "outputId": "24805067-a3c7-4461-8485-82f126a6046b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "amazon = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/domain_adaptation_master/office-31/fc6/amazon_fc6.mat')\n",
        "webcam = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/domain_adaptation_master/office-31/fc6/webcam_fc6.mat')\n",
        "dslr = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/domain_adaptation_master/office-31/fc6/dslr_fc6.mat')\n",
        "cal  = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/domain_adaptation_master/office-31/fc6/caltech_decaf.mat')\n"
      ],
      "metadata": {
        "id": "kk0OvFF5j9HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_fts,amazon_labels=amazon['fts'],amazon['labels'].reshape(-1)-1\n",
        "webcam_fts,webcam_labels=webcam['fts'],webcam['labels'].reshape(-1)-1\n",
        "dslr_fts,dslr_labels=dslr['fts'],dslr['labels'].reshape(-1)-1\n",
        "cal_fts,cal_labels=cal['feas'],cal['labels'].reshape(-1)-1"
      ],
      "metadata": {
        "id": "8ZfiayxsckQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define functions to formulate the training and testing sets"
      ],
      "metadata": {
        "id": "KFLiyU5DcmyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice\n",
        "class_set=np.array([1,2,6,11,12,13,16,17,18,23])-1\n",
        "#backpack, bike, calculator, headphones, keyboard, laptop-computer, monitor, mouse, mu, and projector\n",
        "\n",
        "def get_data(domain_name):\n",
        "  index=np.array([])\n",
        "  label_for_training=[]\n",
        "  fts,labels=None, None\n",
        "  if domain_name=='amazon':\n",
        "    fts,labels=amazon_fts,amazon_labels\n",
        "  elif domain_name=='webcam':\n",
        "    fts,labels=webcam_fts,webcam_labels\n",
        "  elif domain_name=='dslr':\n",
        "    fts,labels=dslr_fts,dslr_labels\n",
        "\n",
        "  j=0\n",
        "  for i in class_set:\n",
        "    index=np.hstack((index,np.where(labels==i)[0]))\n",
        "    for a in np.where(labels==i)[0]:\n",
        "      label_for_training.append(j)\n",
        "    j=j+1\n",
        "  index=index.astype(int)\n",
        "  return fts[index],np.array(label_for_training)\n",
        "\n",
        "def get_index(feature,labels,select_num):\n",
        "  select_list=np.array([])\n",
        "  remaining_list=np.array([])\n",
        "  for i in range(10):\n",
        "    full_list=np.where(labels==i)[0]\n",
        "    ran_select=np.random.choice(full_list,select_num,replace=False)\n",
        "    select_list=np.hstack((select_list,ran_select))\n",
        "\n",
        "\n",
        "    remain_list=np.setdiff1d(full_list,ran_select)\n",
        "    remaining_list=np.hstack((remaining_list,remain_list))\n",
        "  return select_list.astype(int),remaining_list.astype(int)\n",
        "\n",
        "  \n",
        "def souce_target_split(src_name, tar_name):\n",
        "  if src_name =='cad':\n",
        "    src_fea,src_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "    src_fea,src_label=get_data(src_name)\n",
        "  if tar_name == 'cad':\n",
        "    tar_fea,tar_label=np.array(cal_fts),np.array(cal_labels)\n",
        "  else:\n",
        "    tar_fea,tar_label=get_data(tar_name)\n",
        "\n",
        "  if src_name=='amazon':\n",
        "    scr_number=20\n",
        "  elif src_name=='cad':\n",
        "    scr_number=20\n",
        "  else:\n",
        "    scr_number=8\n",
        "  tar_number=3\n",
        "  \n",
        "  src_select,src_remain=get_index(src_fea,src_label,scr_number)\n",
        "  tar_select,tar_remain=get_index(tar_fea,tar_label,tar_number)\n",
        "  \n",
        "\n",
        "  return src_fea[src_select],src_label[src_select],tar_fea[tar_select],tar_label[tar_select],tar_fea[tar_remain],tar_label[tar_remain]"
      ],
      "metadata": {
        "id": "bNIGxwB8kLXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Generate training pairs"
      ],
      "metadata": {
        "id": "KiH_JOdBdBSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization.Create_Pairs\n",
        "class TrainSet(Dataset):\n",
        "    def __init__(self, src_name, tar_name):\n",
        "        self.train_x_scr,self.train_y_scr,self.train_x_tar,self.train_y_tar,self.test_x_tar,self.test_y_tar = souce_target_split(src_name, tar_name)\n",
        "                \n",
        "        Training_P=[]\n",
        "        Training_N=[]\n",
        "        for trs in range(len(self.train_y_scr)):\n",
        "            for trt in range(len(self.train_y_tar)):\n",
        "                if self.train_y_scr[trs] == self.train_y_tar[trt]:\n",
        "                    Training_P.append([trs,trt, 1])\n",
        "                else:\n",
        "                    Training_N.append([trs,trt, 0])\n",
        "        print(\"Class P : \", len(Training_P), \" N : \", len(Training_N))\n",
        "        \n",
        "        random.shuffle(Training_N)\n",
        "        self.imgs = Training_P+Training_N[:3*len(Training_P)]\n",
        "        random.shuffle(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_idx, tgt_idx, domain = self.imgs[idx]\n",
        "\n",
        "        x_src, y_src = self.train_x_scr[src_idx], self.train_y_scr[src_idx]\n",
        "        x_tgt, y_tgt = self.train_x_tar[tgt_idx], self.train_y_tar[tgt_idx]\n",
        "\n",
        "        x_src = torch.from_numpy(x_src)\n",
        "        x_tgt = torch.from_numpy(x_tgt)\n",
        "\n",
        "        return x_src, y_src, x_tgt, y_tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "class TestSet(Dataset):\n",
        "    def __init__(self, src_name, tar_name):\n",
        "        self.train_x_scr,self.train_y_scr,self.train_x_tar,self.train_y_tar,self.test_x_tar,self.test_y_tar = souce_target_split(src_name, tar_name)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.test_x_tar[idx], self.test_y_tar[idx]\n",
        "        x = torch.from_numpy(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.test_x_tar)"
      ],
      "metadata": {
        "id": "IsDWs_yikPw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Define the network"
      ],
      "metadata": {
        "id": "r6i7nG5ldDIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Linear(4096, 1024)\n",
        "        self.act1= nn.PReLU()\n",
        "        self.layer2 = nn.Linear(1024, 128)\n",
        "        self.act2= nn.PReLU()\n",
        "        self.ip2 = nn.Linear(128, 10)\n",
        "  \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 4096)\n",
        "        x = self.layer1(x)\n",
        "        x = self.act1(x)\n",
        "        feature = self.layer2(x)\n",
        "        feature = self.act2(feature)\n",
        "        ip2 = self.ip2(feature)\n",
        "        return feature , ip2\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "YFIc4UHJkS_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define d-SNE loss"
      ],
      "metadata": {
        "id": "sNV4p-2pdEIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dsne_loss(src_feature, src_label, target_feature, target_label):\n",
        "        \"\"\"Pytorch implementation of d-SNE loss.\n",
        "        Original Mxnet implementation found at https://github.com/aws-samples/d-SNE.\n",
        "        @param y_true: tuple or array of two elements, containing source and target features\n",
        "        @param y_pred: tuple or array of two elements, containing source and taget labels\n",
        "        \"\"\"\n",
        "        xs = src_feature\n",
        "        xt = target_feature\n",
        "        ys = src_label    \n",
        "        yt = target_label\n",
        "\n",
        "        batch_size = ys.size()[0]\n",
        "        embed_size = xs.size()[1]\n",
        "\n",
        "        # The original implementation provided an optional feature-normalisation (L2) here. We'll skip it\n",
        "\n",
        "        xs_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(xs, dim=0), size=(batch_size, batch_size, embed_size)\n",
        "        )\n",
        "        xt_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(xt, dim=1), size=(batch_size, batch_size, embed_size)\n",
        "        )\n",
        "\n",
        "        dists = torch.sum(torch.square(xt_rpt - xs_rpt), dim=2)\n",
        "\n",
        "        yt_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(yt, dim=1), size=(batch_size, batch_size)\n",
        "        )\n",
        "        ys_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(ys, dim=0), size=(batch_size, batch_size)\n",
        "        )\n",
        "\n",
        "        y_same = torch.eq(yt_rpt, ys_rpt)\n",
        "        y_diff = torch.ne(yt_rpt, ys_rpt)\n",
        "\n",
        "        intra_cls_dists = torch.mul(dists, y_same)\n",
        "        inter_cls_dists = torch.mul(dists, y_diff)\n",
        "\n",
        "        max_dists = torch.max(dists, dim=1, keepdims=True)[0]\n",
        "        max_dists = torch.broadcast_to(max_dists, size=(batch_size, batch_size))\n",
        "        \n",
        "\n",
        "\n",
        "        revised_inter_cls_dists = torch.where(y_same, max_dists, inter_cls_dists)\n",
        "\n",
        "        max_intra_cls_dist,_ = torch.max(intra_cls_dists, dim=1)\n",
        "        min_inter_cls_dist,_ = torch.min(revised_inter_cls_dists, dim=1)\n",
        "\n",
        "        loss = torch.nn.functional.relu(max_intra_cls_dist - min_inter_cls_dist + 1)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "tyq8yN9fkVNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Define the function for training and testing "
      ],
      "metadata": {
        "id": "mJWxfMK9dRDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune(model, dataloaders, optimizer,loss_weight):\n",
        "    n_epoch = 100\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    since = time.time()\n",
        "    best_acc = 0\n",
        "    stop = 0\n",
        "    max_acc=[]\n",
        "    for epoch in range(0, n_epoch):\n",
        "        stop += 1\n",
        "        for phase in ['src']:\n",
        "            if phase == 'src':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            total_loss, total_center,correct = 0, 0,0\n",
        "            for src_img, src_label, target_img, target_label in dataloaders[phase]:\n",
        "                src_img, src_label, target_img, target_label = src_img.cuda(), src_label.cuda(), target_img.cuda(), target_label.cuda()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'src'):\n",
        "                    src_img = src_img.to(torch.float32)\n",
        "                    target_img = target_img.to(torch.float32)\n",
        "                    src_feat, src_pre = model(src_img)\n",
        "                    tgt_feat, tgt_pre = model(target_img)\n",
        "                    softmax=criterion(src_pre, src_label)\n",
        "                    dsne = dsne_loss(src_feat, src_label, tgt_feat, target_label)\n",
        "                    loss = (1-loss_weight) * softmax + loss_weight * dsne\n",
        "                if phase == 'src':\n",
        "                    loss.backward(torch.ones_like(loss))\n",
        "                    optimizer.step()\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        for inputs, labels in dataloaders['tar']:\n",
        "          inputs, labels= inputs.cuda(),labels.cuda()\n",
        "          inputs = inputs.to(torch.float32)\n",
        "          ip1, outputs = model(inputs)\n",
        "          preds = torch.max(outputs, 1)[1]\n",
        "          correct += torch.sum(preds == labels.data)\n",
        "        epoch_acc = correct.double() / len(dataloaders['tar'].dataset)\n",
        "        if epoch>97:\n",
        "          print('Testing acc:',epoch_acc.item())\n",
        "        max_acc.append(epoch_acc)\n",
        "    print(max(max_acc))\n",
        "    time_pass = time.time() - since\n",
        "    print(f'Training complete in {time_pass // 60:.0f}m {time_pass % 60:.0f}s')"
      ],
      "metadata": {
        "id": "73zMS49Rkdzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Define evaluation function"
      ],
      "metadata": {
        "id": "2dWdTbVddgQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(src_name,tar_name,seeds):\n",
        "  batch_size = 24\n",
        "  n_class=10\n",
        "  #'amazon', 'webcam','dslr','cad'\n",
        "\n",
        "  random.seed(seeds) #amend if you want\n",
        "\n",
        "  train_set = TrainSet(src_name, tar_name)\n",
        "  train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  test_set = TestSet(src_name, tar_name)\n",
        "  test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  print(\"Dataset Length Train : \", len(train_set), \" Test : \", len(test_set))\n",
        "\n",
        "  model = Net().cuda()\n",
        "  param_group = []\n",
        "  learning_rate = 0.0001\n",
        "  momentum = 5e-4\n",
        "  for k, v in model.named_parameters():\n",
        "\n",
        "\n",
        "    if k.__contains__('classifier'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "    elif k.__contains__('ip'):\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "\n",
        "    else:\n",
        "        param_group += [{'params': v, 'lr': learning_rate}]\n",
        "\n",
        "  optimizer = torch.optim.Adam(param_group)\n",
        "  \n",
        "  dataloaders = {'src': train_loader,\n",
        "               'tar': test_loader}\n",
        "  finetune(model, dataloaders, optimizer,0.25)"
      ],
      "metadata": {
        "id": "Q7stobu6k8MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Example"
      ],
      "metadata": {
        "id": "zjhPsgkMdoEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example below is the *Amaon and DSLR* domain adaptation task.\n",
        "You may change the value of variables to get other experimental results.\n",
        "\n",
        "Note that models will be trained from scratch. Training time should last for around **3 minutes** for one repetition if you use the GPU (GeForce RTX 3090).\n",
        "\n",
        "Although the results you get may be slightly different from the ones of the manuscript due to randomized initialization, the gap should be small."
      ],
      "metadata": {
        "id": "o02Lx_-KdpDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "source_domain='amazon'\n",
        "target_domain='dslr'\n",
        "random_seed=1\n",
        "evaluate(source_domain,target_domain,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vdutWugk9b3",
        "outputId": "5a07e3a5-4cba-4f04-8b6b-76aabd5f18de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class P :  600  N :  5400\n",
            "Dataset Length Train :  2400  Test :  127\n",
            "Testing acc: 0.905511811023622\n",
            "Testing acc: 0.905511811023622\n",
            "tensor(0.9134, device='cuda:0', dtype=torch.float64)\n",
            "Training complete in 1m 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#'amazon', 'webcam','dslr','cad'\n",
        "source_domain='dslr'\n",
        "target_domain='amazon'\n",
        "random_seed=1\n",
        "evaluate(source_domain,target_domain,random_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwp34HL5dv7-",
        "outputId": "d6a507a3-30fa-4d1b-86af-8e8c2c3f154c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class P :  240  N :  2160\n",
            "Dataset Length Train :  960  Test :  928\n",
            "Testing acc: 0.7844827586206896\n",
            "Testing acc: 0.7844827586206896\n",
            "tensor(0.7866, device='cuda:0', dtype=torch.float64)\n",
            "Training complete in 0m 60s\n"
          ]
        }
      ]
    }
  ]
}