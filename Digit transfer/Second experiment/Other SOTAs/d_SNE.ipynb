{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "d_SNE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the packages"
      ],
      "metadata": {
        "id": "hNlGp4AUyoNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "AtBPZ7lwyrlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the function used to load MNIST and USPS data splits; as well as to create data pairs"
      ],
      "metadata": {
        "id": "JHhfjwD6ysND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You need to download[ MNIST-USPS data splits](https://github.com/samotiian/CCSA) generated in [1] to run this code. Then: \n",
        "\n",
        "\n",
        "2.1. If you run the code on Colab, you will need to put these splits in the corresponding folder of your [Google Drive](https://drive.google.com/drive/u/0/my-drive).\n",
        "\n",
        "\n",
        "2.2. If you run the code locally, you will need to put these splits in the corresponding folder of your device.\n",
        "\n",
        "\n",
        "\n",
        "[1] Motiian, S., Piccirilli, M., Adjeroh, D. A., & Doretto, G. (2017). Unified deep supervised domain adaptation and generalization. In Proceedings of the IEEE international conference on computer vision (pp. 5715-5725)."
      ],
      "metadata": {
        "id": "-xTkvOAOy1cs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZx1unqLBxv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd63285d-fd42-4159-b500-908ddd02089e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount the Google drive, please ignore this cell if you run the code locally.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Direct the path to where you put the data\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/domain_adaptation_master\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3AN5Y3wCIpV",
        "outputId": "b0c8a64f-5062-426c-f11c-9d82e26fb5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/domain_adaptation_master\n",
            "baseline  cad  fc_6  mnist_m.tar.gz  MNIST_to_USPS  office-31  row_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class to read the data and create pairs for training\n",
        "\n",
        "class TrainSet(Dataset):\n",
        "    def __init__(self, domain_adaptation_task, repetition, sample_per_class):\n",
        "        x_source_path = './row_data/' + domain_adaptation_task + '_X_train_source_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class) + '.npy'\n",
        "        y_source_path = './row_data/' + domain_adaptation_task + '_y_train_source_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class) + '.npy'\n",
        "        x_target_path = './row_data/' + domain_adaptation_task + '_X_train_target_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class) + '.npy'\n",
        "        y_target_path = './row_data/' + domain_adaptation_task + '_y_train_target_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class) + '.npy'\n",
        "\n",
        "        self.x_source=np.load(x_source_path)\n",
        "        self.y_source=np.load(y_source_path)\n",
        "        self.x_target=np.load(x_target_path)\n",
        "        self.y_target=np.load(y_target_path)\n",
        "\n",
        "        print(\"Source X : \", len(self.x_source), \" Y : \", len(self.y_source))\n",
        "        print(\"Target X : \", len(self.x_target), \" Y : \", len(self.y_target))\n",
        "                \n",
        "        Training_P=[]\n",
        "        Training_N=[]\n",
        "        for trs in range(len(self.y_source)):\n",
        "            for trt in range(len(self.y_target)):\n",
        "                if self.y_source[trs] == self.y_target[trt]:\n",
        "                    Training_P.append([trs,trt, 1])\n",
        "                else:\n",
        "                    Training_N.append([trs,trt, 0])\n",
        "        print(\"Class P : \", len(Training_P), \" N : \", len(Training_N))\n",
        "        \n",
        "        random.shuffle(Training_N)\n",
        "        self.imgs = Training_P+Training_N[:3*len(Training_P)]\n",
        "        random.shuffle(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_idx, tgt_idx, domain = self.imgs[idx]\n",
        "\n",
        "        x_src, y_src = self.x_source[src_idx], self.y_source[src_idx]\n",
        "        x_tgt, y_tgt = self.x_target[tgt_idx], self.y_target[tgt_idx]\n",
        "\n",
        "        x_src = torch.from_numpy(x_src).unsqueeze(0)\n",
        "        x_tgt = torch.from_numpy(x_tgt).unsqueeze(0)\n",
        "\n",
        "        return x_src, y_src, x_tgt, y_tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "class TestSet(Dataset):\n",
        "    def __init__(self, domain_adaptation_task, repetition, sample_per_class):\n",
        "        self.x_test = np.load('./row_data/' + domain_adaptation_task + '_X_test_target_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class)+'.npy')\n",
        "        self.y_test = np.load('./row_data/' + domain_adaptation_task + '_y_test_target_repetition_' + str(repetition) + '_sample_per_class_' + str(sample_per_class)+'.npy')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.x_test[idx], self.y_test[idx]\n",
        "        x = torch.from_numpy(x).unsqueeze(0)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_test)"
      ],
      "metadata": {
        "id": "oClhoTwECP7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define LetNet++ for MNIST-USPS"
      ],
      "metadata": {
        "id": "OGqiFR7wn1u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1_1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "    self.prelu1_1 = nn.PReLU()\n",
        "    self.conv1_2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
        "    self.prelu1_2 = nn.PReLU()\n",
        "    self.conv2_1 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "    self.prelu2_1 = nn.PReLU()\n",
        "    self.conv2_2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "    self.prelu2_2 = nn.PReLU()\n",
        "    self.conv3_1 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
        "    self.prelu3_1 = nn.PReLU()\n",
        "    self.conv3_2 = nn.Conv2d(128, 128, kernel_size=5, padding=2)\n",
        "    self.prelu3_2 = nn.PReLU()\n",
        "    self.preluip1 = nn.PReLU()\n",
        "    self.ip1 = nn.Linear(128*2*2, 84)\n",
        "    self.ip2 = nn.Linear(84, 10, bias=False)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.prelu1_1(self.conv1_1(x))\n",
        "    x = self.prelu1_2(self.conv1_2(x))\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.prelu2_1(self.conv2_1(x))\n",
        "    x = self.prelu2_2(self.conv2_2(x))\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.prelu3_1(self.conv3_1(x))\n",
        "    x = self.prelu3_2(self.conv3_2(x))\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = x.view(-1, 128*2*2)\n",
        "    ip1 = self.preluip1(self.ip1(x))\n",
        "    ip2 = self.ip2(ip1)\n",
        "    return F.log_softmax(ip2, dim=1), ip1"
      ],
      "metadata": {
        "id": "akrgEXBECTvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define d-SNE Loss"
      ],
      "metadata": {
        "id": "FiGma5Lqn3P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dnse_loss(src_feature, src_label, target_feature, target_label):\n",
        "        \"\"\"Pytorch implementation of d-SNE loss.\n",
        "        Original Mxnet implementation found at https://github.com/aws-samples/d-SNE.\n",
        "        @param y_true: tuple or array of two elements, containing source and target features\n",
        "        @param y_pred: tuple or array of two elements, containing source and taget labels\n",
        "        \"\"\"\n",
        "        xs = src_feature\n",
        "        xt = target_feature\n",
        "        ys = src_label    \n",
        "        yt = target_label\n",
        "\n",
        "        batch_size = ys.size()[0]\n",
        "        embed_size = xs.size()[1]\n",
        "\n",
        "        # The original implementation provided an optional feature-normalisation (L2) here. We'll skip it\n",
        "\n",
        "        xs_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(xs, dim=0), size=(batch_size, batch_size, embed_size)\n",
        "        )\n",
        "        xt_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(xt, dim=1), size=(batch_size, batch_size, embed_size)\n",
        "        )\n",
        "\n",
        "        dists = torch.sum(torch.square(xt_rpt - xs_rpt), dim=2)\n",
        "\n",
        "        yt_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(yt, dim=1), size=(batch_size, batch_size)\n",
        "        )\n",
        "        ys_rpt = torch.broadcast_to(\n",
        "            torch.unsqueeze(ys, dim=0), size=(batch_size, batch_size)\n",
        "        )\n",
        "\n",
        "        y_same = torch.eq(yt_rpt, ys_rpt)\n",
        "        y_diff = torch.ne(yt_rpt, ys_rpt)\n",
        "\n",
        "        intra_cls_dists = torch.mul(dists, y_same)\n",
        "        inter_cls_dists = torch.mul(dists, y_diff)\n",
        "\n",
        "        max_dists = torch.max(dists, dim=1, keepdims=True)[0]\n",
        "        max_dists = torch.broadcast_to(max_dists, size=(batch_size, batch_size))\n",
        "        \n",
        "\n",
        "\n",
        "        revised_inter_cls_dists = torch.where(y_same, max_dists, inter_cls_dists)\n",
        "\n",
        "        max_intra_cls_dist,_ = torch.max(intra_cls_dists, dim=1)\n",
        "        min_inter_cls_dist,_ = torch.min(revised_inter_cls_dists, dim=1)\n",
        "\n",
        "        loss = torch.nn.functional.relu(max_intra_cls_dist - min_inter_cls_dist + 1)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "5fq-jJJyIOwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Training function"
      ],
      "metadata": {
        "id": "49mvgPuwojWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "domain_adaptation_task = 'MNIST_to_USPS'\n",
        "sample_per_class = 2  # 1 to 7\n",
        "repetition = 9        # The number of splits, i.e., 0 to 9\n",
        "batch = 256\n",
        "epochs = 100\n",
        "alpha = 0.25    # Trade-off: Î»\n",
        "\n",
        "train_set = TrainSet(domain_adaptation_task, repetition, sample_per_class)\n",
        "train_set_loader = DataLoader(train_set, batch_size=batch, shuffle=True, drop_last=True)\n",
        "test_set = TestSet(domain_adaptation_task, repetition, sample_per_class)\n",
        "test_official_loader = DataLoader(test_set, batch_size=batch, shuffle=True, drop_last=True)\n",
        "print(\"Dataset Length Train : \", len(train_set), \" Test : \", len(test_set))\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "net = Network().to(device)\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(net.parameters())\n",
        "\n",
        "\n",
        "def train(net, loader):\n",
        "    net.train()\n",
        "    for i, (src_img, src_label, target_img, target_label) in enumerate(loader):\n",
        "        src_img, target_img = (x.to(device, dtype=torch.float) for x in [src_img, target_img])\n",
        "        src_label, target_label = (x.to(device, dtype=torch.long) for x in [src_label, target_label])\n",
        "        src_pred, src_feature = net(src_img)\n",
        "        _, target_feature = net(target_img)\n",
        "        \n",
        "        ce  = ce_loss(src_pred, src_label)\n",
        "        dsne = dnse_loss(src_feature, src_label, target_feature, target_label)                                          \n",
        "        loss = (1 - alpha) * ce + alpha * dsne\n",
        "        optim.zero_grad()\n",
        "        loss.backward(torch.ones_like(loss))\n",
        "        optim.step()\n",
        "\n",
        "def test(net, loader):\n",
        "    correct = 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for img, label in loader:\n",
        "            img = img.to(device, dtype=torch.float)\n",
        "            label = label.to(device, dtype=torch.long)\n",
        "            pred, _ = net(img)\n",
        "            _, idx = pred.max(dim=1)\n",
        "            correct += (idx == label).sum().cpu().item()\n",
        "    acc = correct / len(loader.dataset)\n",
        "    return acc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOHicUrRCYvd",
        "outputId": "f598bd19-4646-48af-e1d5-d797f754ab07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source X :  2000  Y :  2000\n",
            "Target X :  20  Y :  20\n",
            "Class P :  4000  N :  36000\n",
            "Dataset Length Train :  16000  Test :  1800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Example"
      ],
      "metadata": {
        "id": "M8DCuto8o9ZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below is an example of N=2, i.e., two sample per class from the target domain, on the task of MNIST to USPS.\n",
        "\n",
        "You may change the value of variables to get other experimental results.\n",
        "\n",
        "Note that when N gets larger, the training time **quadratically** increases.\n"
      ],
      "metadata": {
        "id": "5q8qvkAdpXQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Task:', domain_adaptation_task)\n",
        "print(\"Number of samples from target domain:\", sample_per_class)\n",
        "print(\"Repetiton n.o:\",repetition)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(net, train_set_loader)\n",
        "    test_acc = test(net, test_official_loader)\n",
        "    if epoch>95:\n",
        "      print('Train_loss:',train_loss)\n",
        "      print(\"Epoch[%d] testing acc : %.4f\"%(epoch, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaTmhd6Do4Mk",
        "outputId": "684ad319-99f2-4fc0-a29a-78b522215888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: MNIST_to_USPS\n",
            "Number of samples from target domain: 2\n",
            "Repetiton n.o: 9\n",
            "Train_loss: None\n",
            "Epoch[96] testing acc : 0.8694\n",
            "Train_loss: None\n",
            "Epoch[97] testing acc : 0.8689\n",
            "Train_loss: None\n",
            "Epoch[98] testing acc : 0.8694\n",
            "Train_loss: None\n",
            "Epoch[99] testing acc : 0.8694\n"
          ]
        }
      ]
    }
  ]
}