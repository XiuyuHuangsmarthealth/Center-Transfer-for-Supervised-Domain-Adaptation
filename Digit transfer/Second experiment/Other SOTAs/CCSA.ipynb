{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CCSA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNkTlEBNuuX-"
      },
      "source": [
        "1. Load the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q9kZzsO0iuP"
      },
      "source": [
        "import random\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Lambda, Convolution2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adadelta, Nadam\n",
        "from keras import backend as K\n",
        "import numpy   as np\n",
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtZ9DAbhxjDu"
      },
      "source": [
        "2. Define the function used to load MNIST and USPS data splits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "You need to download[ MNIST-USPS data splits](https://github.com/samotiian/CCSA) generated in [1] to run this code. Then: \n",
        "\n",
        "\n",
        "2.1. If you run the code on Colab, you will need to put these splits in the corresponding folder of your [Google Drive](https://drive.google.com/drive/u/0/my-drive).\n",
        "\n",
        "\n",
        "2.2. If you run the code locally, you will need to put these splits in the corresponding folder of your device.\n",
        "\n",
        "\n",
        "\n",
        "[1] Motiian, S., Piccirilli, M., Adjeroh, D. A., & Doretto, G. (2017). Unified deep supervised domain adaptation and generalization. In Proceedings of the IEEE international conference on computer vision (pp. 5715-5725)."
      ],
      "metadata": {
        "id": "w8uB_ONi1ZwJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE_jUudKxqE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3243d0-a145-4c67-95c4-c391c9e00424"
      },
      "source": [
        "# Mount the Google drive, please ignore this cell if you run the code locally.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9_jHR5OCMC"
      },
      "source": [
        "\n",
        "initial_path='/content/drive/MyDrive/MINIST domain adaptation/CCSA-master/row_data/'\n",
        "\n",
        "def printn(string):\n",
        "    sys.stdout.write(string)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def Create_Pairs(domain_adaptation_task,repetition,sample_per_class):\n",
        "\n",
        "    UM  = domain_adaptation_task\n",
        "    cc  = repetition\n",
        "    SpC = sample_per_class\n",
        "\n",
        "    if UM != 'MNIST_to_USPS':\n",
        "        if UM != 'USPS_to_MNIST':\n",
        "            raise Exception('domain_adaptation_task should be either MNIST_to_USPS or USPS_to_MNIST')\n",
        "\n",
        "\n",
        "    if cc <0 or cc>10:\n",
        "        raise Exception('number of repetition should be between 0 and 9.')\n",
        "\n",
        "    if SpC <1 or SpC>7:\n",
        "            raise Exception('number of sample_per_class should be between 1 and 7.')\n",
        "\n",
        "\n",
        "    print('Creating pairs for repetition: '+str(cc)+' and sample_per_class: '+str(sample_per_class))\n",
        "\n",
        "    X_train_target=np.load(initial_path + UM + '_X_train_target_repetition_' + str(cc) + '_sample_per_class_' + str(SpC) + '.npy')\n",
        "    y_train_target=np.load(initial_path + UM + '_y_train_target_repetition_' + str(cc) + '_sample_per_class_' + str(SpC) + '.npy')\n",
        "\n",
        "    X_train_source=np.load(initial_path + UM + '_X_train_source_repetition_' + str(cc) + '_sample_per_class_' + str(SpC) + '.npy')\n",
        "    y_train_source=np.load(initial_path + UM + '_y_train_source_repetition_' + str(cc) + '_sample_per_class_' + str(SpC) + '.npy')\n",
        "\n",
        "\n",
        "\n",
        "    Training_P=[]\n",
        "    Training_N=[]\n",
        "\n",
        "\n",
        "    for trs in range(len(y_train_source)):\n",
        "        for trt in range(len(y_train_target)):\n",
        "            if y_train_source[trs]==y_train_target[trt]:\n",
        "                Training_P.append([trs,trt])\n",
        "            else:\n",
        "                Training_N.append([trs,trt])\n",
        "\n",
        "\n",
        "    random.shuffle(Training_N)\n",
        "    Training = Training_P+Training_N[:3*len(Training_P)]\n",
        "    random.shuffle(Training)\n",
        "\n",
        "\n",
        "    X1=np.zeros([len(Training),16,16],dtype='float32')\n",
        "    X2=np.zeros([len(Training),16,16],dtype='float32')\n",
        "\n",
        "    y1=np.zeros([len(Training)])\n",
        "    y2=np.zeros([len(Training)])\n",
        "    yc=np.zeros([len(Training)])\n",
        "\n",
        "    for i in range(len(Training)):\n",
        "        in1,in2=Training[i]\n",
        "        X1[i,:,:]=X_train_source[in1,:,:]\n",
        "        X2[i,:,:]=X_train_target[in2,:,:]\n",
        "\n",
        "        y1[i]=y_train_source[in1]\n",
        "        y2[i]=y_train_target[in2]\n",
        "        if y_train_source[in1]==y_train_target[in2]:\n",
        "            yc[i]=1\n",
        "\n",
        "    if not os.path.exists('./pairs'):\n",
        "        os.makedirs('./pairs')\n",
        "\n",
        "    np.save('./pairs/' + UM + '_X1_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy', X1)\n",
        "    np.save('./pairs/' + UM + '_X2_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy', X2)\n",
        "\n",
        "    np.save('./pairs/' + UM + '_y1_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy', y1)\n",
        "    np.save('./pairs/' + UM + '_y2_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy', y2)\n",
        "    np.save('./pairs/' + UM + '_yc_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy', yc)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define networks and functions for training"
      ],
      "metadata": {
        "id": "rxysILcY2NU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def Create_Model():\n",
        "\n",
        "    img_rows, img_cols = 16, 16\n",
        "    # nb_filters = 32\n",
        "    pool_size = (2, 2)\n",
        "    kernel_size = (5, 5)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(Convolution2D(32, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Convolution2D(64, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(Convolution2D(64, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Convolution2D(128, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(Convolution2D(128, (kernel_size[0], kernel_size[1]),\n",
        "                            padding ='same',\n",
        "                            input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.PReLU())\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(84))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    eps = 1e-08\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), eps))\n",
        "\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
        "\n",
        "\n",
        "def training_the_model(model,domain_adaptation_task,repetition,sample_per_class):\n",
        "    nb_classes=10\n",
        "    UM = domain_adaptation_task\n",
        "    cc = repetition\n",
        "    SpC = sample_per_class\n",
        "\n",
        "    if UM != 'MNIST_to_USPS':\n",
        "        if UM != 'USPS_to_MNIST':\n",
        "            raise Exception('domain_adaptation_task should be either MNIST_to_USPS or USPS_to_MNIST')\n",
        "\n",
        "    if cc < 0 or cc > 10:\n",
        "        raise Exception('number of repetition should be between 0 and 9.')\n",
        "\n",
        "    if SpC < 1 or SpC > 7:\n",
        "        raise Exception('number of sample_per_class should be between 1 and 7.')\n",
        "\n",
        "\n",
        "    epoch = 100  # Epoch number\n",
        "    batch_size = 256\n",
        "\n",
        "    X_test = np.load(initial_path + UM + '_X_test_target_repetition_' + str(cc) + '_sample_per_class_' + str(SpC)+'.npy')\n",
        "    y_test = np.load(initial_path + UM + '_y_test_target_repetition_' + str(cc) + '_sample_per_class_' + str(SpC)+'.npy')\n",
        "    X_test = X_test.reshape(X_test.shape[0], 16, 16, 1)\n",
        "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "\n",
        "    X1 = np.load('./pairs/' + UM + '_X1_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy')\n",
        "    X2 = np.load('./pairs/' + UM + '_X2_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy')\n",
        "\n",
        "\n",
        "\n",
        "    X1 = X1.reshape(X1.shape[0], 16, 16, 1)\n",
        "    X2 = X2.reshape(X2.shape[0], 16, 16, 1)\n",
        "\n",
        "    y1 = np.load('./pairs/' + UM + '_y1_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy')\n",
        "    y2 = np.load('./pairs/' + UM + '_y2_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy')\n",
        "    yc = np.load('./pairs/' + UM + '_yc_count_' + str(cc) + '_SpC_' + str(SpC) + '.npy')\n",
        "\n",
        "    y1 = np_utils.to_categorical(y1, nb_classes)\n",
        "    y2 = np_utils.to_categorical(y2, nb_classes)\n",
        "\n",
        "    print('Training the model - Epoch '+str(epoch))\n",
        "    nn=batch_size\n",
        "    # best_Acc = 0\n",
        "    best_Acc = []\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # if e % 10 == 0:\n",
        "        #     printn(str(e) + '->')\n",
        "        for i in range(int(len(y2) / nn)):\n",
        "            loss = model.train_on_batch([X1[i * nn:(i + 1) * nn, :, :, :], X2[i * nn:(i + 1) * nn, :, :, :]],\n",
        "                                        [y1[i * nn:(i + 1) * nn, :], yc[i * nn:(i + 1) * nn, ]])\n",
        "            loss = model.train_on_batch([X2[i * nn:(i + 1) * nn, :, :, :], X1[i * nn:(i + 1) * nn, :, :, :]],\n",
        "                                        [y2[i * nn:(i + 1) * nn, :], yc[i * nn:(i + 1) * nn, ]])\n",
        "\n",
        "        Out = model.predict([X_test, X_test])\n",
        "        Acc_v = np.argmax(Out[0], axis=1) - np.argmax(y_test, axis=1)\n",
        "        Acc = (len(Acc_v) - np.count_nonzero(Acc_v) + .0000001) / len(Acc_v)\n",
        "        print('Epoch:',e,\"Loss:\",loss,\"testing acc:\",Acc)\n",
        "        \n",
        "        print('========')\n",
        "\n",
        "    return best_Acc"
      ],
      "metadata": {
        "id": "ad0bGDIF2Ny3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Example"
      ],
      "metadata": {
        "id": "xvv64ddZ2WaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below is an example of N=2, i.e., two samples per class from the target domain, on the task of MNIST to USPS.\n",
        "\n",
        "You may change the value of variables to get other experimental results.\n",
        "\n",
        "Note that when N gets larger, the training time **quadratically** increases.\n"
      ],
      "metadata": {
        "id": "mSP0DQCp2bZm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFqhEu9GYCYe",
        "outputId": "4a51193f-0a05-43f7-d1e3-1075e7c67fc9"
      },
      "source": [
        "\n",
        "\n",
        "# let's assume MNIST->USPS task.\n",
        "domain_adaptation_task = 'MNIST_to_USPS'   # USPS_to_MNIST is also another option.\n",
        "\n",
        "# let's run the experiments when 1 target sample per calss is available in training.\n",
        "# you can run the experiments for sample_per_class=1, ... , 7.\n",
        "sample_per_class = 2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adadelta(learning_rate=0.025, rho=0.95, epsilon=1e-07)\n",
        "\n",
        "\n",
        "print('Domain Adaptation Task: ' + domain_adaptation_task)\n",
        "# let's create the positive and negative pairs using row data.\n",
        "# pairs will be saved in ./pairs directory\n",
        "\n",
        "for repetition in range(9,10):  # amend as 10 for all repetition\n",
        "    # size of digits 16*16\n",
        "    img_rows, img_cols = 16, 16\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    input_a = Input(shape=input_shape)\n",
        "    input_b = Input(shape=input_shape)\n",
        "\n",
        "\n",
        "    # number of classes for digits classification\n",
        "    nb_classes = 10\n",
        "\n",
        "    # Loss = (1-alpha)Classification_Loss + (alpha)CSA\n",
        "    alpha = 0.25\n",
        "    \n",
        "    # Creating embedding function. This corresponds to the function g in the paper.\n",
        "    # You may need to change the network parameters.\n",
        "    model1=Create_Model()\n",
        "\n",
        "    # Having two streams. One for source and one for target.\n",
        "    processed_a = model1(input_a)\n",
        "    processed_b = model1(input_b)\n",
        "\n",
        "\n",
        "    # Creating the prediction function. This corresponds to h in the paper.\n",
        "    out1 = Dropout(0.5)(processed_a)\n",
        "    out1 = Dense(nb_classes)(out1)\n",
        "    out1 = Activation('softmax', name='classification')(out1)\n",
        "\n",
        "\n",
        "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape, name='CSA')(\n",
        "    [processed_a, processed_b])\n",
        "    model = Model(inputs=[input_a, input_b], outputs=[out1, distance])\n",
        "    # model.summary()\n",
        "    model.compile(loss={'classification': 'categorical_crossentropy', 'CSA': contrastive_loss},\n",
        "              optimizer=opt,\n",
        "              loss_weights={'classification': 1 - alpha, 'CSA': alpha})\n",
        "    Create_Pairs(domain_adaptation_task,repetition,sample_per_class)\n",
        "    Acc=training_the_model(model,domain_adaptation_task,repetition,sample_per_class)\n",
        "\n",
        "\n",
        "    print('Best accuracy for {} target sample per class and repetition {} is {}.'.format(sample_per_class,repetition,Acc ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domain Adaptation Task: MNIST_to_USPS\n",
            "Creating pairs for repetition: 9 and sample_per_class: 2\n",
            "Training the model - Epoch 100\n",
            "Epoch: 0 Loss: [1.6262743473052979, 2.0978236198425293, 0.21162639558315277] testing acc: 0.3005555556111111\n",
            "========\n",
            "Epoch: 1 Loss: [0.9305417537689209, 1.045890212059021, 0.5844966173171997] testing acc: 0.6627777778333334\n",
            "========\n",
            "Epoch: 2 Loss: [0.522926926612854, 0.45536211133003235, 0.7256214022636414] testing acc: 0.7638888889444445\n",
            "========\n",
            "Epoch: 3 Loss: [0.34322166442871094, 0.23956705629825592, 0.6541855335235596] testing acc: 0.8138888889444444\n",
            "========\n",
            "Epoch: 4 Loss: [0.2872052490711212, 0.18433813750743866, 0.5958065986633301] testing acc: 0.8300000000555556\n",
            "========\n",
            "Epoch: 5 Loss: [0.24634680151939392, 0.1431727111339569, 0.5558691024780273] testing acc: 0.8400000000555556\n",
            "========\n",
            "Epoch: 6 Loss: [0.22582417726516724, 0.13149316608905792, 0.508817195892334] testing acc: 0.8450000000555556\n",
            "========\n",
            "Epoch: 7 Loss: [0.20087526738643646, 0.11085709184408188, 0.4709298014640808] testing acc: 0.8472222222777778\n",
            "========\n",
            "Epoch: 8 Loss: [0.18033140897750854, 0.09391986578702927, 0.4395660161972046] testing acc: 0.8505555556111112\n",
            "========\n",
            "Epoch: 9 Loss: [0.17455381155014038, 0.09485876560211182, 0.4136389195919037] testing acc: 0.8505555556111112\n",
            "========\n",
            "Epoch: 10 Loss: [0.1525942087173462, 0.0757032111287117, 0.38326722383499146] testing acc: 0.8544444445\n",
            "========\n",
            "Epoch: 11 Loss: [0.15052081644535065, 0.07965999841690063, 0.3631032705307007] testing acc: 0.8550000000555557\n",
            "========\n",
            "Epoch: 12 Loss: [0.1299740970134735, 0.057475872337818146, 0.3474687933921814] testing acc: 0.8577777778333334\n",
            "========\n",
            "Epoch: 13 Loss: [0.1272638589143753, 0.06084071099758148, 0.32653331756591797] testing acc: 0.8600000000555555\n",
            "========\n",
            "Epoch: 14 Loss: [0.11811015009880066, 0.052997931838035583, 0.3134468197822571] testing acc: 0.8577777778333334\n",
            "========\n",
            "Epoch: 15 Loss: [0.11500173807144165, 0.05310416966676712, 0.30069443583488464] testing acc: 0.8600000000555555\n",
            "========\n",
            "Epoch: 16 Loss: [0.11236666142940521, 0.054468102753162384, 0.2860623300075531] testing acc: 0.858333333388889\n",
            "========\n",
            "Epoch: 17 Loss: [0.10401780158281326, 0.04663722589612007, 0.27615952491760254] testing acc: 0.8644444445\n",
            "========\n",
            "Epoch: 18 Loss: [0.09696630388498306, 0.04116380214691162, 0.2643738090991974] testing acc: 0.863333333388889\n",
            "========\n",
            "Epoch: 19 Loss: [0.09115607291460037, 0.03714268282055855, 0.25319623947143555] testing acc: 0.8650000000555556\n",
            "========\n",
            "Epoch: 20 Loss: [0.09091353416442871, 0.03688737750053406, 0.25299200415611267] testing acc: 0.8677777778333334\n",
            "========\n",
            "Epoch: 21 Loss: [0.08977438509464264, 0.037917111068964005, 0.24534618854522705] testing acc: 0.8644444445\n",
            "========\n",
            "Epoch: 22 Loss: [0.08546029031276703, 0.03691192343831062, 0.23110537230968475] testing acc: 0.868333333388889\n",
            "========\n",
            "Epoch: 23 Loss: [0.07885157316923141, 0.03043709322810173, 0.22409501671791077] testing acc: 0.8688888889444445\n",
            "========\n",
            "Epoch: 24 Loss: [0.07710468769073486, 0.030245695263147354, 0.2176816761493683] testing acc: 0.8700000000555556\n",
            "========\n",
            "Epoch: 25 Loss: [0.07959862053394318, 0.032472845166921616, 0.22097596526145935] testing acc: 0.8655555556111112\n",
            "========\n",
            "Epoch: 26 Loss: [0.07443489134311676, 0.030438758432865143, 0.20642328262329102] testing acc: 0.8705555556111112\n",
            "========\n",
            "Epoch: 27 Loss: [0.07291239500045776, 0.031564489006996155, 0.1969561129808426] testing acc: 0.8705555556111112\n",
            "========\n",
            "Epoch: 28 Loss: [0.06992505490779877, 0.027175961062312126, 0.19817234575748444] testing acc: 0.8666666667222223\n",
            "========\n",
            "Epoch: 29 Loss: [0.06540213525295258, 0.02333206683397293, 0.1916123479604721] testing acc: 0.868333333388889\n",
            "========\n",
            "Epoch: 30 Loss: [0.0639062374830246, 0.02268829569220543, 0.1875600665807724] testing acc: 0.8700000000555556\n",
            "========\n",
            "Epoch: 31 Loss: [0.06363700330257416, 0.023805391043424606, 0.1831318438053131] testing acc: 0.8727777778333333\n",
            "========\n",
            "Epoch: 32 Loss: [0.06243221461772919, 0.024234328418970108, 0.17702586948871613] testing acc: 0.8711111111666667\n",
            "========\n",
            "Epoch: 33 Loss: [0.06140657886862755, 0.023567965254187584, 0.1749224215745926] testing acc: 0.8705555556111112\n",
            "========\n",
            "Epoch: 34 Loss: [0.057603009045124054, 0.020840782672166824, 0.16788968443870544] testing acc: 0.8711111111666667\n",
            "========\n",
            "Epoch: 35 Loss: [0.0541662871837616, 0.018390879034996033, 0.1614925116300583] testing acc: 0.8716666667222223\n",
            "========\n",
            "Epoch: 36 Loss: [0.05437035858631134, 0.019335195422172546, 0.15947584807872772] testing acc: 0.8772222222777778\n",
            "========\n",
            "Epoch: 37 Loss: [0.050955455750226974, 0.015885334461927414, 0.15616582334041595] testing acc: 0.8744444445\n",
            "========\n",
            "Epoch: 38 Loss: [0.052278414368629456, 0.01898389309644699, 0.15216197073459625] testing acc: 0.8766666667222223\n",
            "========\n",
            "Epoch: 39 Loss: [0.0485951229929924, 0.014682549051940441, 0.15033283829689026] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 40 Loss: [0.04813944548368454, 0.01606362871825695, 0.14436689019203186] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 41 Loss: [0.04590367525815964, 0.014193066395819187, 0.14103549718856812] testing acc: 0.8755555556111112\n",
            "========\n",
            "Epoch: 42 Loss: [0.04503161460161209, 0.014791835099458694, 0.13575094938278198] testing acc: 0.8755555556111112\n",
            "========\n",
            "Epoch: 43 Loss: [0.045412708073854446, 0.015437654219567776, 0.13533787429332733] testing acc: 0.8766666667222223\n",
            "========\n",
            "Epoch: 44 Loss: [0.044206589460372925, 0.014090048149228096, 0.13455620408058167] testing acc: 0.878333333388889\n",
            "========\n",
            "Epoch: 45 Loss: [0.0419449582695961, 0.014163719490170479, 0.12528866529464722] testing acc: 0.8777777778333333\n",
            "========\n",
            "Epoch: 46 Loss: [0.04099438339471817, 0.014549520798027515, 0.12032896280288696] testing acc: 0.8744444445\n",
            "========\n",
            "Epoch: 47 Loss: [0.03771112859249115, 0.009812657721340656, 0.12140654027462006] testing acc: 0.8777777778333333\n",
            "========\n",
            "Epoch: 48 Loss: [0.03961307555437088, 0.012258951552212238, 0.12167545408010483] testing acc: 0.8750000000555556\n",
            "========\n",
            "Epoch: 49 Loss: [0.03693298622965813, 0.010632311925292015, 0.11583501100540161] testing acc: 0.8777777778333333\n",
            "========\n",
            "Epoch: 50 Loss: [0.03760702535510063, 0.012660246342420578, 0.11244736611843109] testing acc: 0.8766666667222223\n",
            "========\n",
            "Epoch: 51 Loss: [0.03513580188155174, 0.009970222599804401, 0.11063253879547119] testing acc: 0.8750000000555556\n",
            "========\n",
            "Epoch: 52 Loss: [0.037055086344480515, 0.01308361068367958, 0.10896950960159302] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 53 Loss: [0.03296898677945137, 0.009730514138936996, 0.10268440842628479] testing acc: 0.8766666667222223\n",
            "========\n",
            "Epoch: 54 Loss: [0.032540637999773026, 0.00978571642190218, 0.10080540180206299] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 55 Loss: [0.033763617277145386, 0.012692800723016262, 0.09697606414556503] testing acc: 0.878333333388889\n",
            "========\n",
            "Epoch: 56 Loss: [0.032648198306560516, 0.010253403335809708, 0.09983257949352264] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 57 Loss: [0.029982460662722588, 0.007583135738968849, 0.09718043357133865] testing acc: 0.8761111111666667\n",
            "========\n",
            "Epoch: 58 Loss: [0.029983531683683395, 0.00969348382204771, 0.09085367619991302] testing acc: 0.8772222222777778\n",
            "========\n",
            "Epoch: 59 Loss: [0.03021618351340294, 0.009736750274896622, 0.09165447950363159] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 60 Loss: [0.02946593426167965, 0.009733268991112709, 0.08866392821073532] testing acc: 0.8766666667222223\n",
            "========\n",
            "Epoch: 61 Loss: [0.029783057048916817, 0.010853469371795654, 0.0865718200802803] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 62 Loss: [0.028219612315297127, 0.008572377264499664, 0.08716131746768951] testing acc: 0.878333333388889\n",
            "========\n",
            "Epoch: 63 Loss: [0.027838105335831642, 0.008517509326338768, 0.08579989522695541] testing acc: 0.8750000000555556\n",
            "========\n",
            "Epoch: 64 Loss: [0.02649635821580887, 0.008695372380316257, 0.07989931106567383] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 65 Loss: [0.025796659290790558, 0.008285287767648697, 0.07833077013492584] testing acc: 0.8800000000555556\n",
            "========\n",
            "Epoch: 66 Loss: [0.025444909930229187, 0.007908265106379986, 0.07805484533309937] testing acc: 0.8794444445\n",
            "========\n",
            "Epoch: 67 Loss: [0.025979194790124893, 0.008423581719398499, 0.07864603400230408] testing acc: 0.878333333388889\n",
            "========\n",
            "Epoch: 68 Loss: [0.02451770380139351, 0.007557983510196209, 0.07539686560630798] testing acc: 0.8794444445\n",
            "========\n",
            "Epoch: 69 Loss: [0.02447686903178692, 0.007471861317753792, 0.07549189031124115] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 70 Loss: [0.02317206747829914, 0.007010490167886019, 0.07165680080652237] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 71 Loss: [0.022745970636606216, 0.007276485674083233, 0.06915442645549774] testing acc: 0.8800000000555556\n",
            "========\n",
            "Epoch: 72 Loss: [0.022651541978120804, 0.006732083857059479, 0.07040991634130478] testing acc: 0.883333333388889\n",
            "========\n",
            "Epoch: 73 Loss: [0.021685047075152397, 0.006886338349431753, 0.06608117371797562] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 74 Loss: [0.02206842228770256, 0.006972684524953365, 0.06735564023256302] testing acc: 0.8794444445\n",
            "========\n",
            "Epoch: 75 Loss: [0.02260761149227619, 0.008212457410991192, 0.06579307466745377] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 76 Loss: [0.021105673164129257, 0.006596442777663469, 0.06463336199522018] testing acc: 0.8800000000555556\n",
            "========\n",
            "Epoch: 77 Loss: [0.020526140928268433, 0.0063894386403262615, 0.06293624639511108] testing acc: 0.8788888889444445\n",
            "========\n",
            "Epoch: 78 Loss: [0.020162105560302734, 0.006096369586884975, 0.062359314411878586] testing acc: 0.8827777778333333\n",
            "========\n",
            "Epoch: 79 Loss: [0.01960914582014084, 0.005522993393242359, 0.061867605894804] testing acc: 0.8822222222777778\n",
            "========\n",
            "Epoch: 80 Loss: [0.02021690085530281, 0.006678923033177853, 0.06083083525300026] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 81 Loss: [0.019303221255540848, 0.005848843604326248, 0.05966635420918465] testing acc: 0.8800000000555556\n",
            "========\n",
            "Epoch: 82 Loss: [0.019361531361937523, 0.007212559226900339, 0.05580844730138779] testing acc: 0.8827777778333333\n",
            "========\n",
            "Epoch: 83 Loss: [0.019403260201215744, 0.007257542572915554, 0.05584041774272919] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 84 Loss: [0.018384160473942757, 0.006227582227438688, 0.0548538938164711] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 85 Loss: [0.018360279500484467, 0.006363445892930031, 0.05435078218579292] testing acc: 0.8816666667222223\n",
            "========\n",
            "Epoch: 86 Loss: [0.01824050210416317, 0.006348385009914637, 0.05391685292124748] testing acc: 0.8838888889444445\n",
            "========\n",
            "Epoch: 87 Loss: [0.018217340111732483, 0.005959688685834408, 0.054990291595458984] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 88 Loss: [0.017638852819800377, 0.0064586978405714035, 0.051179319620132446] testing acc: 0.8805555556111112\n",
            "========\n",
            "Epoch: 89 Loss: [0.016840489581227303, 0.005093540996313095, 0.052081335335969925] testing acc: 0.8827777778333333\n",
            "========\n",
            "Epoch: 90 Loss: [0.01714407280087471, 0.006138261873275042, 0.05016150325536728] testing acc: 0.8811111111666667\n",
            "========\n",
            "Epoch: 91 Loss: [0.01631581410765648, 0.005484859924763441, 0.04880867898464203] testing acc: 0.8811111111666667\n",
            "========\n",
            "Epoch: 92 Loss: [0.01579962484538555, 0.0048126536421477795, 0.048760540783405304] testing acc: 0.8816666667222223\n",
            "========\n",
            "Epoch: 93 Loss: [0.015262434259057045, 0.004255896434187889, 0.04828204959630966] testing acc: 0.8838888889444445\n",
            "========\n",
            "Epoch: 94 Loss: [0.015316818840801716, 0.004799115005880594, 0.04686992987990379] testing acc: 0.883333333388889\n",
            "========\n",
            "Epoch: 95 Loss: [0.015472300350666046, 0.00483762426301837, 0.04737633094191551] testing acc: 0.8838888889444445\n",
            "========\n",
            "Epoch: 96 Loss: [0.015434686094522476, 0.005502553656697273, 0.045231085270643234] testing acc: 0.883333333388889\n",
            "========\n",
            "Epoch: 97 Loss: [0.014817288145422935, 0.0048518311232328415, 0.04471366107463837] testing acc: 0.8816666667222223\n",
            "========\n",
            "Epoch: 98 Loss: [0.015031036920845509, 0.005170847289264202, 0.044611606746912] testing acc: 0.8822222222777778\n",
            "========\n",
            "Epoch: 99 Loss: [0.014110993593931198, 0.004212243482470512, 0.043807245790958405] testing acc: 0.8838888889444445\n",
            "========\n",
            "Best accuracy for 2 target sample per class and repetition 9 is [].\n"
          ]
        }
      ]
    }
  ]
}